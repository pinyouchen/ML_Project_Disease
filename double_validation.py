import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from joblib import load

# å¼•ç”¨æ‚¨çš„æ¨¡çµ„
from processors import DataProcessor
from normative_modeling import NormativeModeler

# è¨­å®šç¹ªåœ–é¢¨æ ¼
sns.set_theme(style="whitegrid", context="talk")
plt.rcParams['font.sans-serif'] = ['Arial', 'Microsoft JhengHei', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

def run_double_validation(train_run_dir, file_path, sheet_name, target_hrv='SDNN'):
    print("="*70)
    print(f"ğŸš€ å•Ÿå‹•é›™é‡é©—è­‰ (Double Validation)")
    print(f"   æ¨¡å‹ä¾†æº: {train_run_dir}")
    print(f"   ç”Ÿç†æŒ‡æ¨™: {target_hrv}")
    print("="*70)

    # 1. æº–å‚™è¼¸å‡ºè³‡æ–™å¤¾
    out_dir = os.path.join(train_run_dir, "double_validation")
    os.makedirs(out_dir, exist_ok=True)

    # 2. è¼‰å…¥è³‡æ–™
    # é€™è£¡æˆ‘å€‘éœ€è¦æ‰€æœ‰è³‡æ–™ä¾†åšåˆ†æ
    df = pd.read_excel(file_path, sheet_name=sheet_name)
    
    # åˆå§‹åŒ–è™•ç†å™¨ (ç‚ºäº†åšç‰¹å¾µå·¥ç¨‹)
    processor = DataProcessor(file_path, sheet_name, mode='all')
    processor.df = df
    processor.prepare_features_and_labels() # ç”¢ç”Ÿ HRV_Mean, Ratio ç­‰ç‰¹å¾µ
    
    # 3. å»ºç«‹å¸¸æ¨¡ (Normative Model) - å–å¾— Z-Score
    print(f"\n[1/2] å»ºç«‹ {target_hrv} å¸¸æ¨¡...")
    norm_modeler = NormativeModeler(file_path, sheet_name, target=target_hrv, log_transform=True)
    if not norm_modeler.load_data(): return
    norm_modeler.train_health_model()
    norm_modeler.predict_deviations()
    
    # å–å¾— Z-Score èˆ‡ Traffic Light
    norm_modeler.apply_traffic_light_system()
    df_norm = norm_modeler.df[['Z_Score', 'Traffic_Light']].copy()
    
    # 4. è¼‰å…¥åˆ†é¡å™¨ (Classifier) - å–å¾— é æ¸¬æ©Ÿç‡
    print(f"\n[2/2] è¼‰å…¥åˆ†é¡æ¨¡å‹èˆ‡é æ¸¬...")
    
    models_dir = os.path.join(train_run_dir, "models")
    disease_labels = ['SSD', 'MDD', 'Panic', 'GAD']
    
    for label in disease_labels:
        print(f"\nğŸ” åˆ†æç–¾ç—…: {label}")
        meta_path = os.path.join(models_dir, f"{label}_best.json")
        if not os.path.exists(meta_path):
            print(f"   âš ï¸ æ‰¾ä¸åˆ° {label} çš„æ¨¡å‹ï¼Œè·³éã€‚")
            continue
            
        with open(meta_path, 'r', encoding='utf-8') as f: meta = json.load(f)
        
        # è¼‰å…¥æ¨¡å‹èˆ‡è½‰æ›å™¨
        model = load(os.path.join(models_dir, meta['files']['model']))
        scaler = load(os.path.join(models_dir, meta['files']['scaler'])) if meta['files']['scaler'] else None
        imputer = load(os.path.join(models_dir, meta['files']['imputer'])) if meta['files']['imputer'] else None
        
        # æº–å‚™ X (é‡å°è©²æ¨¡å‹éœ€è¦çš„ç‰¹å¾µ)
        # æ³¨æ„ï¼šé€™è£¡æˆ‘å€‘å°"å…¨é«”è³‡æ–™"åšé æ¸¬ï¼Œçœ‹çœ‹åˆ†ä½ˆ
        X_test = processor.apply_external_transform(
            processor.X, meta['feature_columns'], meta['outlier_bounds'], imputer, scaler
        )
        
        # é æ¸¬æ©Ÿç‡
        try:
            probs = model.predict_proba(X_test)[:, 1]
        except:
            print(f"   âš ï¸ æ¨¡å‹ä¸æ”¯æ´æ©Ÿç‡é æ¸¬ï¼Œè·³éã€‚")
            continue
            
        # --- 5. æ•´åˆæ•¸æ“š (Merge) ---
        # æˆ‘å€‘åªåˆ†æã€Œè‡¨åºŠç¢ºè¨ºç‚ºç–¾ç—…çµ„ã€çš„äººï¼Œçœ‹çœ‹ AI è·Ÿ å¸¸æ¨¡ æ€éº¼èªªä»–å€‘
        # (ç•¶ç„¶ä¹Ÿå¯ä»¥çœ‹å…¨é«”ï¼Œä½†çœ‹ç–¾ç—…çµ„æœ€æœ‰æ„ç¾©)
        mask_disease = df[label] == 1
        
        analysis_df = pd.DataFrame({
            'Probability': probs[mask_disease],  # Xè»¸: åˆ†é¡å™¨ä¿¡å¿ƒ
            'Z_Score': df_norm.loc[mask_disease, 'Z_Score'], # Yè»¸: ç”Ÿç†åå·®
            'Traffic_Light': df_norm.loc[mask_disease, 'Traffic_Light']
        })
        
        if len(analysis_df) == 0: continue

        # --- 6. ç¹ªè£½é›™é‡é©—è­‰åœ– (2D Plot) ---
        plt.figure(figsize=(10, 8))
        
        # ç•«è±¡é™åˆ†éš”ç·š
        # Xè»¸åˆ‡åˆ†é»: 0.5 (æˆ–æ¨¡å‹çš„æœ€ä½³ threshold)
        th = meta.get('threshold', 0.5)
        plt.axvline(th, color='gray', linestyle='--', linewidth=1, label=f'Clf Threshold ({th:.2f})')
        
        # Yè»¸åˆ‡åˆ†é»: -1.96 (ç”Ÿç†ç•°å¸¸ç·š)
        plt.axhline(-1.96, color='red', linestyle='--', linewidth=1, label='Physio Abnormal (-1.96)')
        
        # æ•£ä½ˆåœ–
        # æ ¹æ“šç´…ç¶ ç‡ˆä¸Šè‰²
        colors = {'Green': 'green', 'Yellow': 'orange', 'Red': 'red'}
        sns.scatterplot(data=analysis_df, x='Probability', y='Z_Score', 
                        hue='Traffic_Light', palette=colors, style='Traffic_Light', 
                        s=80, alpha=0.7)
        
        # æ¨™è¨»è±¡é™æ„ç¾©
        # å³ä¸‹ (High Prob, Low Z): é›™é‡ç¢ºè¨º
        plt.text(0.95, -3, "Double Confirmed\n(Physio+)", ha='right', va='bottom', fontsize=12, color='darkred', fontweight='bold')
        # å³ä¸Š (High Prob, Normal Z): å¿ƒç†/èªçŸ¥å‹
        plt.text(0.95, 1, "Psychological Type\n(Physio-)", ha='right', va='top', fontsize=12, color='darkblue')
        # å·¦ä¸‹ (Low Prob, Low Z): æ¼ç¶²ä¹‹é­š
        plt.text(0.05, -3, "Missed Risk\n(Physio+)", ha='left', va='bottom', fontsize=12, color='darkorange', fontweight='bold')
        
        plt.title(f'Double Validation: {label} vs {target_hrv}', fontsize=15)
        plt.xlabel(f'Classifier Probability (Model Confidence)')
        plt.ylabel(f'{target_hrv} Z-Score (Physiological Status)')
        plt.xlim(0, 1)
        plt.ylim(-4, 4)
        plt.legend(loc='upper left', bbox_to_anchor=(1, 1))
        plt.tight_layout()
        
        save_path = os.path.join(out_dir, f"DoubleValid_{label}_{target_hrv}.png")
        plt.savefig(save_path, dpi=300)
        plt.close()
        print(f"   ğŸ“Š åœ–è¡¨å·²å„²å­˜: {save_path}")
        
        # è¨ˆç®—ã€Œæ¼ç¶²ä¹‹é­šã€æ¯”ä¾‹ (AI åˆ¤ < Thï¼Œä½† Z < -1.96)
        missed = analysis_df[(analysis_df['Probability'] < th) & (analysis_df['Z_Score'] < -1.96)]
        print(f"   ğŸ” ç™¼ç¾ {len(missed)} ä½æ½›åœ¨ç”Ÿç†ç•°å¸¸æ‚£è€…è¢«åˆ†é¡å™¨æ¼åˆ¤ (Low Probability)")

    print(f"\nâœ… é›™é‡é©—è­‰å®Œæˆï¼è«‹æŸ¥çœ‹: {out_dir}")

# ==========================================
# åŸ·è¡Œå€
# ==========================================
if __name__ == "__main__":
    # 1. è¨­å®šæª”æ¡ˆè·¯å¾‘
    FILE_PATH = r"D:\FLY114-main\data.xlsx"
    SHEET_NAME = "Data2"
    
    # 2. è¨­å®šè¨“ç·´å¥½çš„æ¨¡å‹è³‡æ–™å¤¾ (è«‹æ”¹æˆæ‚¨å¯¦éš›è·‘å‡ºä¾†çš„è³‡æ–™å¤¾åç¨±)
    # ä¾‹å¦‚: runs/Run_all_20251130_120000
    # è«‹å‹™å¿…ç¢ºèªé€™å€‹è³‡æ–™å¤¾è£¡æœ‰ models å­è³‡æ–™å¤¾
    TRAIN_RUN_DIR = r"D:\ML_Project\runs\Task5_Full_D2_20251127_151301"  
    
    # 3. é¸æ“‡ä¸€å€‹æœ€å…·ä»£è¡¨æ€§çš„ç”Ÿç†æŒ‡æ¨™ (é€šå¸¸æ˜¯ SDNN æˆ– HF)
    TARGET_HRV = 'SDNN'
    
    if os.path.exists(TRAIN_RUN_DIR):
        run_double_validation(TRAIN_RUN_DIR, FILE_PATH, SHEET_NAME, target_hrv=TARGET_HRV)
    else:
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹è³‡æ–™å¤¾: {TRAIN_RUN_DIR}ï¼Œè«‹ä¿®æ”¹ç¨‹å¼ç¢¼ä¸­çš„è·¯å¾‘ã€‚")